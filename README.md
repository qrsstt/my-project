# my-project by ФБ-32 Сажко Олена
# Звіт по лабораторних роботах з предмету "Аналіз та підготовка даних"

## Структура Репозиторію

* `lab2/`: Містить файл з кодом для лабораторної Роботи №2.
* `lab3/`: Містить файл з кодом для Лабораторної Роботи №3.
* `lab4/`: Містить файл з кодом для Лабораторної Роботи №4.
* `lab5/`: Містить два файли з кодом для Лабораторної Роботи №5.
* `lab6/`: Містить файл з кодом для Лабораторної Роботи №6.
* `.gitignore`: Визначає файли та директорії, які Git повинен ігнорувати.
* `README.md`: Цей файл, що надає загальний опис репозиторію.

## Лабораторна Робота №2: "Наука про дані: Підготовчий етап"

**Мета:** Ознайомитися з основними кроками роботи з даними (workflow) від постановки задачі до підготовки пояснювальної записки. Зрозуміти постановку задачі та природу сирих даних, над якими виконуються аналітичні операції.

**Виконані завдання:**
* **Завантаження VHI-даних:** Для кожної адміністративної одиниці України програмно завантажено тестові структуровані файли, що містять значення VHI-індексу (Vegetation Health Index) з порталу NOAA. 
* **Читання та обробка даних:** Завантажені текстові файли зчитано у фрейми даних Pandas. 
* **Коригування індексів областей:** Реалізовано процедуру для зміни індексів областей, що використовуються на порталі NOAA, на відповідні українські назви.
* **Формування вибірок та аналіз даних:** Розроблено процедури для формування вибірок, що включають елементи аналізу, зокрема:
    * Побудова ряду VHI для вказаної області за вказаний рік.
    * Пошук екстремумів (мінімальних та максимальних значень), середнього та медіани VHI для вказаних областей та періодів.
    * Побудова ряду VHI для вказаного діапазону років для конкретних областей.
    * Визначення років та відповідних областей, впродовж яких екстремальні посухи (VHI < 15) торкнулися більше 20% областей України (5 областей з 25).
* **Організація коду:** Усі процедури реалізовано у вигляді окремих функцій з читабельним виводом, що містить опис завдання та результату.



## Лабораторна Робота №3: "Наука про дані: Обмін результатами та початковий аналіз"

**Мета:** Ознайомитися з системою контролю версій GitHub, навчитися створювати прості веб-додатки для обміну результатами досліджень з використанням модуля Streamlit.

**Виконані завдання:**
* **Створення інтерактивного веб-додатку за допомогою Streamlit:**
    * Розроблено елементи керування для фільтрації даних VHI, включаючи:
        * Dropdown-списки для вибору часових рядів (VCI, TCI, VHI) та області аналізу.
        * Слайдери для зазначення інтервалів тижнів та років.
        * Кнопку для скидання всіх фільтрів до початкового стану.
    * Реалізовано три вкладки для відображення фільтрованих даних:
        * **Таблиця:** Відображення відфільтрованих даних у вигляді таблиці.
        * **Теплова карта:** Відображення часового ряду (VCI, TCI або VHI) у вигляді теплової карти, що показує залежність від року та тижня для обраної області.
        * **Порівняння по регіонах:** Відображення середніх значень обраного часового ряду для всіх областей за вказаний період у вигляді стовпчикової діаграми, з можливістю сортування.
    * Додано функціональність сортування даних за зростанням/спаданням для вибраного часового ряду.
    * Забезпечено ергономічне розміщення інтерактивних елементів в одній колонці, а графіків та таблиці — в іншій.


## Лабораторна Робота №4: "Структури для роботи з великими обсягами даних в Python"

**Мета:** Опанування інструментів для ефективної роботи з великими наборами даних у Python із використанням `numpy` та `pandas`. Порівняння продуктивності, зручності та швидкодії різних структур зберігання даних.


**Короткий опис виконаних завдань**

- **Первинна фільтрація -** відбір записів за потужністю, вольтажем, струмом.
- **Випадкова вибірка -** формування вибірки (500 000 записів) та обчислення середніх значень.
- **Вечірнє споживання -** аналіз записів після 18:00 із додатковою фільтрацією та підбором кожного 3-го/4-го елемента.
- **Обробка пропущених значень -** виявлення, видалення та/або заповнення.
- **Нормалізація та стандартизація -** власні реалізації функцій без сторонніх бібліотек.
- **Візуалізація -** гістограми, графіки залежностей, багатовимірні діаграми.
- **Кореляційний аналіз -** розрахунок коефіцієнтів Пірсона та Спірмена.
- **Кодування категорій -** One Hot Encoding string-ознак.
- **Профілювання часу -** вимірювання часу виконання ключових операцій за допомогою `timeit`.
- **Порівняння платформ -** дублювання завдань у `NumPy` та `pandas`.


**Порівняння продуктивності**

| Завдання                                         | NumPy, сек | Pandas, сек | Зручність (NumPy / Pandas) 
|----------------------------------------------------------------------------------------------------------
| 1. Фільтрація за Global_active_power > 5 kW      | 0.0867     | 0.0069      | 3 / 5                   
| 2. Відбір за Voltage > 235 В                     | 0.0894     | 0.0078      | 3 / 5                   
| 3. Фільтрація за струмом + порівняння субметерів | 0.3277     | 0.0206      | 3 / 5                   
| 4. Випадкова вибірка + середні значення          | 2.0667     | 0.3661      | 3 / 5                   
| 5. Вечірнє споживання + селекція                 | 0.8934     | 0.3476      | 2 / 5               

**Аналіз продуктивності та висновки**

*Швидкість -* у всіх випадках `pandas` працює в рази швидше. Це пояснюється вбудованими оптимізаціями, кращею роботою з DataFrame API, а також готовою підтримкою типів даних.

*Зручність -* `pandas` має значно зручніший та читабельніший синтаксис. Робота з датами, рядками, категоріями реалізована одразу в базовому функціоналі.

*Висновок:*  хоча `numpy` часто вважається швидшим у числових обчисленнях, у випадках складної фільтрації та маніпуляцій з табличними даними `pandas` забезпечує як кращу продуктивність, так і простоту реалізації.
Вибір структури залежить від задачі:
**`pandas`** — найкращий вибір для аналізу CSV, агрегацій, фільтрацій, візуалізацій.
`numpy` — може бути корисним у лінійній алгебрі, масивних обчисленнях без метаданих.


## 📊 Загальна оцінка (5-бальна шкала)

| Критерій                     | NumPy | Pandas |
|------------------------------------------------
| Швидкодія                    |  2.0  | **5.0**|
| Простота синтаксису          |  3.0  | **5.0**|
| Гнучкість при обробці даних  |  3.0  | **5.0**|
| Підтримка datetime/категорій |  1.0  | **5.0**|
| Інтеграція з візуалізацією   |  1.0  | **5.0**|


## Лабораторна робота №5: Візуалізація даних

**Мета:** ознайомлення з сучасними засобами візуалізації даних у Python, інтерактивною взаємодією з графіками через слайдери, кнопки, чекбокси. Дослідження методів фільтрації зашумленого сигналу. Формування практичних навичок зі створення графічних інтерфейсів для аналізу сигналів.

**Виконані завдання**
*Завдання 1: Інтерактивна гармоніка з шумом*

- Побудова графіка зашумленої функції гармоніки:  
  `y(t) = A * sin(ω * t + φ) + noise`
- Інтерфейс реалізовано за допомогою `matplotlib.widgets`, що включає:
  - **Слайдери** для зміни параметрів:
    - амплітуда (`Amplitude`)
    - частота (`Frequency`)
    - фаза (`Phase`)
    - середнє значення шуму (`Noise mean`)
    - дисперсія шуму (`Noise covariance`)
  - **Чекбокс** — вмикання/вимикання шуму
  - **Кнопка Reset** — повертає параметри до початкових значень
- Графік оновлюється при зміні будь-якого параметра
- Шум генерується лише при зміні параметрів шуму — при зміні параметрів гармоніки зберігається попередній шум

*Завдання 2: Фільтрація гармоніки*

- Генерація гармоніки з шумом (аналогічно до завдання 1)
- Застосування **фільтра нижніх частот** до зашумленого сигналу
  - Фільтрація реалізована через:
    - `scipy.signal.butter`
    - `scipy.signal.filtfilt`
- Побудова графіка з:
  - "Чистою" гармонікою
  - Зашумленим сигналом
  - Відфільтрованим сигналом
- Інтерактивна взаємодія через **`ipywidgets`**:
  - Слайдери для зміни параметрів
  - Чекбокс для вмикання фільтрації
- Результати оновлюються у режимі реального часу

## Висновки

У лабораторній роботі було створено інтерактивний застосунок для візуалізації гармонічного сигналу з шумом, що дозволяє змінювати параметри сигналу та шуму в реальному часі. Особливістю є збереження шуму при зміні параметрів, якщо сам шум не змінюється. У другому завданні реалізовано фільтрацію шуму за допомогою фільтра нижніх частот, що значно покращує якість сигналу. Завдяки інтерактивним елементам користувач може налаштовувати параметри фільтра та миттєво бачити результати.



## Лабораторна Робота №6: "Застосування NumPy"

**Мета:** Отримати поглиблені навички роботи з бібліотекою NumPy. Дослідити поняття лінійної регресії та градієнтного спуску, реалізувавши їх програмно.

**Виконані завдання:**
* **Генерація даних:** Згенеровано двовимірні дані `(x, y)` за допомогою `numpy.random`, забезпечивши розподіл точок навколо заздалегідь заданої прямої (`y = kx + b`) для подальшого аналізу.
* **Реалізація методу найменших квадратів:**
    * Написано функцію для обчислення лінійної регресії методом найменших квадратів, що дозволяє знайти оптимальні оцінки коефіцієнтів `k` та `b`.
    * Проведено порівняння знайдених параметрів з оцінкою `numpy.polyfit(x, y, 1)` та з початковими параметрами прямої.
    * Відображено на графіку знайдену лінію регресії; якщо вхідні дані були згенеровані навколо прямої, то її також відображено.
* **Реалізація методу градієнтного спуску:**
    * Написано функцію, що реалізує метод градієнтного спуску для пошуку оптимальних оцінок коефіцієнтів `k` та `b`. Визначено оптимальні вхідні параметри, такі як `learning_rate` та `n_iter`.
    * Додано отриману лінію регресії на загальний графік.
    * Побудовано графік функції втрат від кількості ітерацій, зроблено висновки щодо її збіжності.
    * Порівняно отримані результати методу градієнтного спуску з результатами методу найменших квадратів.



## Використані Технології

**Python:** Основна мова програмування, версія 3.x.
* **Streamlit:** Фреймворк для швидкого створення інтерактивних веб-додатків для візуалізації даних.
* **Pandas:** Бібліотека для аналізу та маніпулювання даними.
* **Matplotlib:** Бібліотека для створення статичних, анімованих та інтерактивних візуалізацій в Python.
* **Seaborn:** Бібліотека для статистичної візуалізації даних, що базується на Matplotlib, яка забезпечує привабливіші та інформативніші графіки.
* **Requests:** Бібліотека для спрощення виконання HTTP-запитів, використовується для завантаження даних з веб-ресурсів.
* **urllib.request:** Модуль стандартної бібліотеки Python для відкриття URL-адрес.
* **NumPy:** Бібліотека для чисельних обчислень, що забезпечує підтримку багатовимірних масивів та матриць, а також високопродуктивні математичні функції для роботи з ними.
* **os:** Модуль стандартної бібліотеки Python, що надає спосіб взаємодії з операційною системою.
* **datetime:** Модуль стандартної бібліотеки Python для роботи з датами та часом.